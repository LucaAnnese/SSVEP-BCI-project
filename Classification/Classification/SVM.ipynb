{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "import pandas as pd\n",
    "import sklearn.model_selection as model_selection\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi = pd.read_csv('inputMM_Means.csv')\n",
    "df = pd.read_csv('inputS_Means.csv')\n",
    "\n",
    "#multi = pd.read_csv('inputMM_PF.csv')\n",
    "#df = pd.read_csv('inputS_PF.csv')\n",
    "\n",
    "#multi = pd.read_csv('inputMM_Max.csv')\n",
    "#df = pd.read_csv('inputS_Max.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>6</th>\n",
       "      <th>6.5</th>\n",
       "      <th>7</th>\n",
       "      <th>7.5</th>\n",
       "      <th>8.2</th>\n",
       "      <th>9.3</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000543</td>\n",
       "      <td>0.001225</td>\n",
       "      <td>0.000789</td>\n",
       "      <td>0.000381</td>\n",
       "      <td>0.001587</td>\n",
       "      <td>0.000611</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001435</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>0.000464</td>\n",
       "      <td>0.000948</td>\n",
       "      <td>0.000913</td>\n",
       "      <td>0.001151</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000484</td>\n",
       "      <td>0.000793</td>\n",
       "      <td>0.000883</td>\n",
       "      <td>0.001108</td>\n",
       "      <td>0.000875</td>\n",
       "      <td>0.000417</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000582</td>\n",
       "      <td>0.000635</td>\n",
       "      <td>0.001143</td>\n",
       "      <td>0.001388</td>\n",
       "      <td>0.000597</td>\n",
       "      <td>0.001538</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000596</td>\n",
       "      <td>0.001177</td>\n",
       "      <td>0.000739</td>\n",
       "      <td>0.001341</td>\n",
       "      <td>0.000582</td>\n",
       "      <td>0.001357</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>0.001052</td>\n",
       "      <td>0.000627</td>\n",
       "      <td>0.000803</td>\n",
       "      <td>0.001280</td>\n",
       "      <td>0.001186</td>\n",
       "      <td>0.002961</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>0.000699</td>\n",
       "      <td>0.000642</td>\n",
       "      <td>0.000541</td>\n",
       "      <td>0.000711</td>\n",
       "      <td>0.000603</td>\n",
       "      <td>0.001773</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>0.000902</td>\n",
       "      <td>0.001029</td>\n",
       "      <td>0.001062</td>\n",
       "      <td>0.000395</td>\n",
       "      <td>0.001268</td>\n",
       "      <td>0.002614</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>0.001458</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.000711</td>\n",
       "      <td>0.000792</td>\n",
       "      <td>0.000641</td>\n",
       "      <td>0.001278</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>0.000745</td>\n",
       "      <td>0.001085</td>\n",
       "      <td>0.000524</td>\n",
       "      <td>0.000423</td>\n",
       "      <td>0.000306</td>\n",
       "      <td>0.001573</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>354 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            6       6.5         7       7.5       8.2       9.3  target\n",
       "0    0.000543  0.001225  0.000789  0.000381  0.001587  0.000611     6.5\n",
       "1    0.001435  0.000491  0.000464  0.000948  0.000913  0.001151     6.5\n",
       "2    0.000484  0.000793  0.000883  0.001108  0.000875  0.000417     6.5\n",
       "3    0.000582  0.000635  0.001143  0.001388  0.000597  0.001538     6.5\n",
       "4    0.000596  0.001177  0.000739  0.001341  0.000582  0.001357     6.5\n",
       "..        ...       ...       ...       ...       ...       ...     ...\n",
       "349  0.001052  0.000627  0.000803  0.001280  0.001186  0.002961     9.3\n",
       "350  0.000699  0.000642  0.000541  0.000711  0.000603  0.001773     9.3\n",
       "351  0.000902  0.001029  0.001062  0.000395  0.001268  0.002614     9.3\n",
       "352  0.001458  0.001387  0.000711  0.000792  0.000641  0.001278     9.3\n",
       "353  0.000745  0.001085  0.000524  0.000423  0.000306  0.001573     9.3\n",
       "\n",
       "[354 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>6</th>\n",
       "      <th>6.5</th>\n",
       "      <th>7</th>\n",
       "      <th>7.5</th>\n",
       "      <th>8.2</th>\n",
       "      <th>9.3</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000935</td>\n",
       "      <td>0.001757</td>\n",
       "      <td>0.001503</td>\n",
       "      <td>0.003940</td>\n",
       "      <td>0.000749</td>\n",
       "      <td>0.000765</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001871</td>\n",
       "      <td>0.000909</td>\n",
       "      <td>0.001816</td>\n",
       "      <td>0.002846</td>\n",
       "      <td>0.001741</td>\n",
       "      <td>0.001715</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002988</td>\n",
       "      <td>0.002231</td>\n",
       "      <td>0.002428</td>\n",
       "      <td>0.004053</td>\n",
       "      <td>0.001861</td>\n",
       "      <td>0.000945</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000854</td>\n",
       "      <td>0.002129</td>\n",
       "      <td>0.001739</td>\n",
       "      <td>0.001381</td>\n",
       "      <td>0.002405</td>\n",
       "      <td>0.001745</td>\n",
       "      <td>8.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002438</td>\n",
       "      <td>0.001480</td>\n",
       "      <td>0.001174</td>\n",
       "      <td>0.000601</td>\n",
       "      <td>0.003877</td>\n",
       "      <td>0.000959</td>\n",
       "      <td>8.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>0.000681</td>\n",
       "      <td>0.000942</td>\n",
       "      <td>0.002176</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>0.000296</td>\n",
       "      <td>0.000698</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>0.001732</td>\n",
       "      <td>0.000875</td>\n",
       "      <td>0.000620</td>\n",
       "      <td>0.000608</td>\n",
       "      <td>0.000826</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>0.001648</td>\n",
       "      <td>0.000898</td>\n",
       "      <td>0.000762</td>\n",
       "      <td>0.001253</td>\n",
       "      <td>0.000694</td>\n",
       "      <td>0.001108</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>0.000606</td>\n",
       "      <td>0.000832</td>\n",
       "      <td>0.000484</td>\n",
       "      <td>0.001111</td>\n",
       "      <td>0.000349</td>\n",
       "      <td>0.000589</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>0.001096</td>\n",
       "      <td>0.002010</td>\n",
       "      <td>0.001193</td>\n",
       "      <td>0.000892</td>\n",
       "      <td>0.001380</td>\n",
       "      <td>0.000631</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            6       6.5         7       7.5       8.2       9.3  target\n",
       "0    0.000935  0.001757  0.001503  0.003940  0.000749  0.000765     7.5\n",
       "1    0.001871  0.000909  0.001816  0.002846  0.001741  0.001715     7.5\n",
       "2    0.002988  0.002231  0.002428  0.004053  0.001861  0.000945     7.5\n",
       "3    0.000854  0.002129  0.001739  0.001381  0.002405  0.001745     8.2\n",
       "4    0.002438  0.001480  0.001174  0.000601  0.003877  0.000959     8.2\n",
       "..        ...       ...       ...       ...       ...       ...     ...\n",
       "295  0.000681  0.000942  0.002176  0.000406  0.000296  0.000698     6.0\n",
       "296  0.001732  0.000875  0.000620  0.000608  0.000826  0.000376     6.0\n",
       "297  0.001648  0.000898  0.000762  0.001253  0.000694  0.001108     6.0\n",
       "298  0.000606  0.000832  0.000484  0.001111  0.000349  0.000589     6.0\n",
       "299  0.001096  0.002010  0.001193  0.000892  0.001380  0.000631     6.0\n",
       "\n",
       "[300 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare the input vectors and the output values\n",
    "X = df.drop(['target'], axis=1)\n",
    "y = df['target']\n",
    "\n",
    "X_multi = df.drop(['target'], axis = 1)\n",
    "y_multi = df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split both dataset into training set and test set\n",
    "\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, train_size = 0.80, test_size = 0.20, random_state = 101)\n",
    "X_multi_train, X_multi_test, y_multi_train, y_multi_test = model_selection.train_test_split(X_multi, y_multi, train_size = 0.80, test_size = 0.20, random_state = 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing single \n",
    "from sklearn import preprocessing\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "encoder.fit(y_train)\n",
    "y_train = encoder.transform(y_train)\n",
    "encoder.fit(y_test)\n",
    "y_test = encoder.transform(y_test)\n",
    "#multi\n",
    "encoder.fit(y_multi_train)\n",
    "y_multi_train = encoder.transform(y_multi_train)\n",
    "encoder.fit(y_multi_test)\n",
    "y_multi_test = encoder.transform(y_multi_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM classic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC(kernel=\"linear\")\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_multi_train, y_multi_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Polynomial Kernel):  23.94\n",
      "F1 (Polynomial Kernel):  9.25\n"
     ]
    }
   ],
   "source": [
    "clf_pred = clf.predict(X_multi_test)\n",
    "clf_accuracy = accuracy_score(y_multi_test, clf_pred)\n",
    "clf_f1 = f1_score(y_multi_test, clf_pred, average='weighted')\n",
    "print('Accuracy (Polynomial Kernel): ', \"%.2f\" % (clf_accuracy*100))\n",
    "print('F1 (Polynomial Kernel): ', \"%.2f\" % (clf_f1*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Polynomial kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters to be optimized with Cross Validation\n",
    "params_grid = [{'kernel' : ['poly'], 'degree' : [x for x in range(1,3)], 'C' : [ 0.01, 0.1, 1, 10, 100]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=SVC(), n_jobs=2,\n",
       "             param_grid=[{'C': [0.01, 0.1, 1, 10, 100], 'degree': [1, 2],\n",
       "                          'kernel': ['poly']}])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_model_pol= GridSearchCV(SVC(), params_grid, cv=3, n_jobs = 2)\n",
    "svm_model_pol.fit(X_train, y_train)\n",
    "svm_model_pol.fit(X_multi_train, y_multi_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=100, degree=1, kernel='poly')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_model_pol.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Polynomial Kernel):  77.46\n",
      "F1 (Polynomial Kernel):  77.59\n"
     ]
    }
   ],
   "source": [
    "svm_pred = svm_model_pol.predict(X_multi_test)\n",
    "svm_accuracy_pol = accuracy_score(y_multi_test, svm_pred)\n",
    "svm_f1_pol = f1_score(y_multi_test, svm_pred, average='weighted')\n",
    "print('Accuracy (Polynomial Kernel): ', \"%.2f\" % (svm_accuracy_pol*100))\n",
    "print('F1 (Polynomial Kernel): ', \"%.2f\" % (svm_f1_pol*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Gaussian Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters to be optimized with Cross Validation\n",
    "gamma_range = [1e-3, 1, 1e3]\n",
    "params_grid = [{'kernel' : ['rbf'], 'gamma' : gamma_range, 'C' : [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=SVC(),\n",
       "             param_grid=[{'C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
       "                          'gamma': [0.001, 1, 1000.0], 'kernel': ['rbf']}])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_model = GridSearchCV(SVC(), params_grid, cv=3)\n",
    "svm_model.fit(X_train, y_train)\n",
    "svm_model.fit(X_multi_train, y_multi_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=100, gamma=1000.0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.00692836, 0.00682306, 0.00785478, 0.00585214, 0.00845663,\n",
       "        0.00816488, 0.00740663, 0.00827567, 0.00881441, 0.00650462,\n",
       "        0.00814358, 0.00688092, 0.00519808, 0.00689514, 0.0061779 ,\n",
       "        0.0042034 , 0.00652528, 0.00891542, 0.00530338, 0.00781743,\n",
       "        0.00552702, 0.00586748, 0.00664862, 0.0051825 ]),\n",
       " 'std_fit_time': array([0.00034128, 0.00093642, 0.00011095, 0.00165966, 0.00029837,\n",
       "        0.00018909, 0.00081305, 0.00017111, 0.00051238, 0.00081315,\n",
       "        0.0002642 , 0.00032823, 0.00069239, 0.00082113, 0.00084526,\n",
       "        0.00039925, 0.0020792 , 0.00086313, 0.00056745, 0.0002483 ,\n",
       "        0.00026536, 0.0017434 , 0.00136528, 0.00109979]),\n",
       " 'mean_score_time': array([0.00376129, 0.0036962 , 0.0044682 , 0.00354346, 0.00452121,\n",
       "        0.00497206, 0.00480151, 0.00427938, 0.00425688, 0.0040795 ,\n",
       "        0.00352971, 0.00322493, 0.00285538, 0.00362229, 0.0029428 ,\n",
       "        0.00334962, 0.00492438, 0.00473301, 0.0039374 , 0.00380961,\n",
       "        0.00259503, 0.00344054, 0.00295266, 0.00312869]),\n",
       " 'std_score_time': array([2.74791729e-04, 1.88824304e-04, 5.61091301e-04, 5.22987021e-04,\n",
       "        5.62241136e-05, 1.08343454e-03, 4.52743301e-04, 3.02363140e-04,\n",
       "        1.50946432e-04, 3.14718384e-04, 2.13825565e-04, 3.32443075e-04,\n",
       "        2.33788217e-04, 9.48113022e-04, 8.48676934e-04, 5.08571972e-04,\n",
       "        2.26700844e-03, 2.68491173e-04, 6.69296975e-04, 2.51644859e-04,\n",
       "        5.09502022e-04, 6.63770408e-04, 7.31575288e-04, 1.25467507e-03]),\n",
       " 'param_C': masked_array(data=[0.0001, 0.0001, 0.0001, 0.001, 0.001, 0.001, 0.01,\n",
       "                    0.01, 0.01, 0.1, 0.1, 0.1, 1, 1, 1, 10, 10, 10, 100,\n",
       "                    100, 100, 1000, 1000, 1000],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_gamma': masked_array(data=[0.001, 1, 1000.0, 0.001, 1, 1000.0, 0.001, 1, 1000.0,\n",
       "                    0.001, 1, 1000.0, 0.001, 1, 1000.0, 0.001, 1, 1000.0,\n",
       "                    0.001, 1, 1000.0, 0.001, 1, 1000.0],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_kernel': masked_array(data=['rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf',\n",
       "                    'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf',\n",
       "                    'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'C': 0.0001, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "  {'C': 0.0001, 'gamma': 1, 'kernel': 'rbf'},\n",
       "  {'C': 0.0001, 'gamma': 1000.0, 'kernel': 'rbf'},\n",
       "  {'C': 0.001, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "  {'C': 0.001, 'gamma': 1, 'kernel': 'rbf'},\n",
       "  {'C': 0.001, 'gamma': 1000.0, 'kernel': 'rbf'},\n",
       "  {'C': 0.01, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "  {'C': 0.01, 'gamma': 1, 'kernel': 'rbf'},\n",
       "  {'C': 0.01, 'gamma': 1000.0, 'kernel': 'rbf'},\n",
       "  {'C': 0.1, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "  {'C': 0.1, 'gamma': 1, 'kernel': 'rbf'},\n",
       "  {'C': 0.1, 'gamma': 1000.0, 'kernel': 'rbf'},\n",
       "  {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "  {'C': 1, 'gamma': 1, 'kernel': 'rbf'},\n",
       "  {'C': 1, 'gamma': 1000.0, 'kernel': 'rbf'},\n",
       "  {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "  {'C': 10, 'gamma': 1, 'kernel': 'rbf'},\n",
       "  {'C': 10, 'gamma': 1000.0, 'kernel': 'rbf'},\n",
       "  {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "  {'C': 100, 'gamma': 1, 'kernel': 'rbf'},\n",
       "  {'C': 100, 'gamma': 1000.0, 'kernel': 'rbf'},\n",
       "  {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "  {'C': 1000, 'gamma': 1, 'kernel': 'rbf'},\n",
       "  {'C': 1000, 'gamma': 1000.0, 'kernel': 'rbf'}],\n",
       " 'split0_test_score': array([0.2       , 0.2       , 0.2       , 0.2       , 0.2       ,\n",
       "        0.2       , 0.2       , 0.2       , 0.2       , 0.2       ,\n",
       "        0.2       , 0.2       , 0.2       , 0.2       , 0.2       ,\n",
       "        0.2       , 0.2       , 0.54736842, 0.2       , 0.2       ,\n",
       "        0.72631579, 0.2       , 0.2       , 0.70526316]),\n",
       " 'split1_test_score': array([0.19148936, 0.19148936, 0.19148936, 0.19148936, 0.19148936,\n",
       "        0.19148936, 0.19148936, 0.19148936, 0.19148936, 0.19148936,\n",
       "        0.19148936, 0.19148936, 0.19148936, 0.19148936, 0.19148936,\n",
       "        0.19148936, 0.19148936, 0.53191489, 0.19148936, 0.19148936,\n",
       "        0.59574468, 0.19148936, 0.19148936, 0.56382979]),\n",
       " 'split2_test_score': array([0.19148936, 0.19148936, 0.19148936, 0.19148936, 0.19148936,\n",
       "        0.19148936, 0.19148936, 0.19148936, 0.19148936, 0.19148936,\n",
       "        0.19148936, 0.19148936, 0.19148936, 0.19148936, 0.19148936,\n",
       "        0.19148936, 0.19148936, 0.57446809, 0.19148936, 0.19148936,\n",
       "        0.64893617, 0.19148936, 0.19148936, 0.63829787]),\n",
       " 'mean_test_score': array([0.19432624, 0.19432624, 0.19432624, 0.19432624, 0.19432624,\n",
       "        0.19432624, 0.19432624, 0.19432624, 0.19432624, 0.19432624,\n",
       "        0.19432624, 0.19432624, 0.19432624, 0.19432624, 0.19432624,\n",
       "        0.19432624, 0.19432624, 0.55125047, 0.19432624, 0.19432624,\n",
       "        0.65699888, 0.19432624, 0.19432624, 0.63579694]),\n",
       " 'std_test_score': array([0.00401195, 0.00401195, 0.00401195, 0.00401195, 0.00401195,\n",
       "        0.00401195, 0.00401195, 0.00401195, 0.00401195, 0.00401195,\n",
       "        0.00401195, 0.00401195, 0.00401195, 0.00401195, 0.00401195,\n",
       "        0.00401195, 0.00401195, 0.0175878 , 0.00401195, 0.00401195,\n",
       "        0.05360945, 0.00401195, 0.00401195, 0.05776701]),\n",
       " 'rank_test_score': array([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 1, 4,\n",
       "        4, 2])}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_model.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Polynomial Kernel):  78.87\n",
      "F1 (Polynomial Kernel):  79.37\n"
     ]
    }
   ],
   "source": [
    "svm_pred = svm_model.predict(X_multi_test)\n",
    "svm_accuracy_gau = accuracy_score(y_multi_test, svm_pred)\n",
    "svm_f1_gau = f1_score(y_multi_test, svm_pred, average='weighted')\n",
    "print('Accuracy (Polynomial Kernel): ', \"%.2f\" % (svm_accuracy_gau*100))\n",
    "print('F1 (Polynomial Kernel): ', \"%.2f\" % (svm_f1_gau*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "x_axis = [\"Linear\", \"Polynomial\", \"Guassian\"]\n",
    "y_axis = [clf_accuracy, svm_accuracy_pol, svm_accuracy_gau]\n",
    "X_axis = np.arange(len(X))\n",
    "X_axis\n",
    "plt.bar(x_axis, y_axis)\n",
    "\n",
    "plt.xticks = (X_axis,x_axis)\n",
    "plt.xlabel(\"Kernels\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"SVM Kernel Comparison Feature: Frequency component\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
